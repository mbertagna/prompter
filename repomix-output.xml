This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
llm_prompt_manager/
  app/
    data/
      prompts.json
    static/
      script.js
      style.css
    templates/
      index.html
    __init__.py
    api.py
    crud.py
    main.py
    models.py
    utils.py
  tests/
    test_api.py
llm_prompt_manager.env/
  bin/
    activate
    activate.csh
    activate.fish
    Activate.ps1
    fastapi
    httpx
    pip
    pip3
    pip3.11
    py.test
    pygmentize
    pytest
    uvicorn
  pyvenv.cfg
.gitattributes
.gitignore
Dockerfile
LICENSE
PLAN.md
pull_and_restart.sh
push_and_restart.sh
README.md
requirements.txt
SPEC.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="llm_prompt_manager/app/static/script.js">
// LLM Prompt Manager Frontend Logic
(function () {
    const apiBase = "/api/prompts"; // trailing slash added by endpoints where needed

    // State
    let prompts = [];
    let selectedPrompt = null;
    let parameterValues = {}; // { [paramName]: value }

    // Elements
    const searchInput = document.getElementById("searchInput");
    const promptList = document.getElementById("promptList");
    const detailTitle = document.getElementById("detailTitle");
    const detailDescription = document.getElementById("detailDescription");
    const parametersContainer = document.getElementById("parametersContainer");
    const assembledOutput = document.getElementById("assembledOutput");
    const copyBtn = document.getElementById("copyBtn");

    const addPromptBtn = document.getElementById("addPromptBtn");
    const editPromptBtn = document.getElementById("editPromptBtn");
    const deletePromptBtn = document.getElementById("deletePromptBtn");

    // Modal elements
    const promptModalEl = document.getElementById("promptModal");
    const promptModal = promptModalEl ? new bootstrap.Modal(promptModalEl) : null;
    const promptIdEl = document.getElementById("promptId");
    const promptTitleEl = document.getElementById("promptTitle");
    const promptDescriptionEl = document.getElementById("promptDescription");
    const promptBaseEl = document.getElementById("promptBase");
    const addParamFieldBtn = document.getElementById("addParamFieldBtn");
    const paramFields = document.getElementById("paramFields");
    const savePromptBtn = document.getElementById("savePromptBtn");
    const promptModalTitle = document.getElementById("promptModalTitle");

    // Utilities
    function sanitize(str) {
        return (str || "").toString();
    }

    function replacePlaceholders(template, values) {
        if (!template) return "";
        return template.replace(/\{\{(.*?)\}\}/g, (_, key) => {
            const trimmed = key.trim();
            return values[trimmed] || "";
        });
    }

    function setButtonsEnabled(enabled) {
        editPromptBtn.disabled = !enabled;
        deletePromptBtn.disabled = !enabled;
        copyBtn.disabled = !enabled;
    }

    // Fetch & Render
    async function loadPrompts() {
        try {
            const res = await fetch(`${apiBase}/`);
            if (!res.ok) throw new Error(`Failed to fetch prompts: ${res.status}`);
            prompts = await res.json();
            renderList();
            // Keep selection if still present
            if (selectedPrompt) {
                const stillExists = prompts.find(p => p.id === selectedPrompt.id);
                if (stillExists) {
                    selectPrompt(stillExists);
                } else {
                    clearDetail();
                }
            }
        } catch (err) {
            console.error(err);
            alert("Failed to load prompts.");
        }
    }

    function renderList(filterText = sanitize(searchInput.value).toLowerCase()) {
        promptList.innerHTML = "";
        const filtered = prompts.filter(p => {
            const title = sanitize(p.title).toLowerCase();
            const desc = sanitize(p.description).toLowerCase();
            return !filterText || title.includes(filterText) || desc.includes(filterText);
        });

        filtered.forEach(p => {
            const li = document.createElement("li");
            li.className = "list-group-item list-group-item-action" + (selectedPrompt && selectedPrompt.id === p.id ? " active" : "");
            li.textContent = p.title;
            li.style.cursor = "pointer";
            li.addEventListener("click", () => selectPrompt(p));
            promptList.appendChild(li);
        });
    }

    function clearDetail() {
        selectedPrompt = null;
        detailTitle.textContent = "Select a prompt";
        detailDescription.textContent = "";
        parametersContainer.innerHTML = "";
        assembledOutput.textContent = "";
        parameterValues = {};
        setButtonsEnabled(false);
        renderList();
    }

    function selectPrompt(prompt) {
        selectedPrompt = prompt;
        renderDetail(prompt);
        setButtonsEnabled(true);
        renderList();
    }

    function renderDetail(prompt) {
        detailTitle.textContent = sanitize(prompt.title);
        detailDescription.textContent = sanitize(prompt.description);
        parametersContainer.innerHTML = "";
        parameterValues = parameterValues || {};

        const parameters = Array.isArray(prompt.parameters) ? prompt.parameters : [];
        parameters.forEach(paramName => {
            const wrapper = document.createElement("div");
            wrapper.className = "mb-2";

            const label = document.createElement("label");
            label.className = "form-label";
            label.textContent = paramName;
            label.setAttribute("for", `param_${paramName}`);

            const textarea = document.createElement("textarea");
            textarea.className = "form-control";
            textarea.id = `param_${paramName}`;
            textarea.value = parameterValues[paramName] || "";
            textarea.addEventListener("input", () => {
                parameterValues[paramName] = textarea.value;
                updateAssembled();
            });

            wrapper.appendChild(label);
            wrapper.appendChild(textarea);
            parametersContainer.appendChild(wrapper);
        });

        updateAssembled();
    }

    function updateAssembled() {
        if (!selectedPrompt) {
            assembledOutput.textContent = "";
            return;
        }
        const output = replacePlaceholders(selectedPrompt.base_prompt, parameterValues);
        assembledOutput.textContent = output;
    }

    // Copy
    async function copyToClipboard() {
        try {
            await navigator.clipboard.writeText(assembledOutput.textContent || "");
        } catch (err) {
            console.error(err);
            alert("Copy failed. Your browser may not allow clipboard access.");
        }
    }

    // Modal Helpers
    function clearModal() {
        if (!promptModal) return;
        promptIdEl.value = "";
        promptTitleEl.value = "";
        promptDescriptionEl.value = "";
        promptBaseEl.value = "";
        paramFields.innerHTML = "";
    }

    function fillModal(prompt) {
        if (!promptModal) return;
        promptIdEl.value = prompt.id || "";
        promptTitleEl.value = sanitize(prompt.title);
        promptDescriptionEl.value = sanitize(prompt.description);
        promptBaseEl.value = sanitize(prompt.base_prompt);
        paramFields.innerHTML = "";
        const parameters = Array.isArray(prompt.parameters) ? prompt.parameters : [];
        parameters.forEach(name => addParamField(name));
    }

    function addParamField(defaultName = "") {
        const row = document.createElement("div");
        row.className = "input-group mb-2";

        const input = document.createElement("input");
        input.type = "text";
        input.className = "form-control";
        input.placeholder = "parameter_name";
        input.value = defaultName;

        const btnWrap = document.createElement("button");
        btnWrap.type = "button";
        btnWrap.className = "btn btn-outline-danger";
        btnWrap.textContent = "Remove";
        btnWrap.addEventListener("click", () => row.remove());

        row.appendChild(input);
        row.appendChild(btnWrap);
        paramFields.appendChild(row);
    }

    function readParametersFromModal() {
        const names = [];
        paramFields.querySelectorAll("input[type='text']").forEach(inp => {
            const name = sanitize(inp.value).trim();
            if (name && !names.includes(name)) names.push(name);
        });
        return names;
    }

    // CRUD
    async function savePrompt() {
        const body = {
            title: sanitize(promptTitleEl.value).trim(),
            description: sanitize(promptDescriptionEl.value).trim(),
            base_prompt: sanitize(promptBaseEl.value),
            parameters: readParametersFromModal()
        };

        const id = sanitize(promptIdEl.value).trim();
        if (id) body.id = id;

        try {
            const res = await fetch(`${apiBase}/`, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify(body)
            });
            if (!res.ok) throw new Error(`Save failed: ${res.status}`);
            const data = await res.json();
            await loadPrompts();
            if (data && data.prompt) {
                // attempt to reselect
                const updated = prompts.find(p => p.id === data.prompt.id);
                if (updated) selectPrompt(updated);
            }
            if (promptModal) promptModal.hide();
        } catch (err) {
            console.error(err);
            alert("Failed to save prompt.");
        }
    }

    async function deleteSelectedPrompt() {
        if (!selectedPrompt) return;
        if (!confirm(`Delete prompt "${selectedPrompt.title}"?`)) return;
        try {
            const res = await fetch(`${apiBase}/${encodeURIComponent(selectedPrompt.id)}`, { method: "DELETE" });
            if (!res.ok) throw new Error(`Delete failed: ${res.status}`);
            await loadPrompts();
            clearDetail();
        } catch (err) {
            console.error(err);
            alert("Failed to delete prompt.");
        }
    }

    // Event bindings
    if (searchInput) {
        searchInput.addEventListener("input", () => renderList());
    }

    if (copyBtn) {
        copyBtn.addEventListener("click", copyToClipboard);
    }

    if (addPromptBtn && promptModal) {
        addPromptBtn.addEventListener("click", () => {
            promptModalTitle.textContent = "Add Prompt";
            clearModal();
            addParamField();
            promptModal.show();
        });
    }

    if (editPromptBtn && promptModal) {
        editPromptBtn.addEventListener("click", () => {
            if (!selectedPrompt) return;
            promptModalTitle.textContent = "Edit Prompt";
            clearModal();
            fillModal(selectedPrompt);
            promptModal.show();
        });
    }

    if (deletePromptBtn) {
        deletePromptBtn.addEventListener("click", deleteSelectedPrompt);
    }

    if (addParamFieldBtn) {
        addParamFieldBtn.addEventListener("click", () => addParamField());
    }

    if (savePromptBtn) {
        savePromptBtn.addEventListener("click", savePrompt);
    }

    // Init
    loadPrompts();
})();
</file>

<file path="llm_prompt_manager/app/static/style.css">
body {
    background-color: #fafafa;
}
</file>

<file path="llm_prompt_manager/app/templates/index.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>LLM Prompt Manager</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/static/style.css">
    <style>
        .sidebar {
            max-height: 70vh;
            overflow-y: auto;
        }
        .parameters textarea {
            min-height: 80px;
        }
        #assembledOutput {
            min-height: 200px;
            white-space: pre-wrap;
        }
    </style>
    <script>
        window.CSRF_DISABLED = true;
    </script>
    <!-- Simple modal templates are defined later in body -->
    <!-- No inline logic here; kept minimal -->
    <!-- Using vanilla JS in /static/script.js -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
</head>
<body class="container-fluid py-3">
    <div class="d-flex align-items-center justify-content-between mb-3">
        <h1 class="h3 m-0">LLM Prompt Manager</h1>
        <div class="d-flex gap-2">
            <button id="addPromptBtn" class="btn btn-primary">Add Prompt</button>
            <button id="editPromptBtn" class="btn btn-outline-secondary" disabled>Edit</button>
            <button id="deletePromptBtn" class="btn btn-outline-danger" disabled>Delete</button>
        </div>
    </div>

    <div class="row g-3">
        <div class="col-md-4">
            <input id="searchInput" type="text" class="form-control mb-2" placeholder="Search prompts...">
            <ul id="promptList" class="list-group sidebar"></ul>
        </div>
        <div class="col-md-8">
            <div id="detailView" class="card">
                <div class="card-body">
                    <h5 id="detailTitle" class="card-title">Select a prompt</h5>
                    <p id="detailDescription" class="text-muted"></p>
                    <div id="parametersContainer" class="parameters"></div>
                    <div class="mt-3">
                        <label class="form-label">Assembled Output</label>
                        <pre id="assembledOutput" class="form-control"></pre>
                    </div>
                    <div class="mt-3 d-flex gap-2">
                        <button id="copyBtn" class="btn btn-success" disabled>Copy</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Add/Edit Modal -->
    <div class="modal fade" id="promptModal" tabindex="-1" aria-hidden="true">
      <div class="modal-dialog modal-lg">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="promptModalTitle">Add Prompt</h5>
            <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
          </div>
          <div class="modal-body">
            <form id="promptForm">
              <input type="hidden" id="promptId">
              <div class="mb-3">
                <label for="promptTitle" class="form-label">Title</label>
                <input type="text" class="form-control" id="promptTitle" required>
              </div>
              <div class="mb-3">
                <label for="promptDescription" class="form-label">Description</label>
                <textarea class="form-control" id="promptDescription" rows="2" required></textarea>
              </div>
              <div class="mb-3">
                <label for="promptBase" class="form-label">Base Prompt</label>
                <textarea class="form-control" id="promptBase" rows="6" required></textarea>
              </div>
              <div class="mb-3">
                <div class="d-flex align-items-center justify-content-between">
                  <label class="form-label m-0">Parameters</label>
                  <button id="addParamFieldBtn" type="button" class="btn btn-sm btn-outline-primary">Add Parameter</button>
                </div>
                <div id="paramFields" class="mt-2"></div>
              </div>
            </form>
          </div>
          <div class="modal-footer">
            <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancel</button>
            <button type="button" id="savePromptBtn" class="btn btn-primary">Save</button>
          </div>
        </div>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
    <script src="/static/script.js"></script>
</body>
</html>
</file>

<file path="llm_prompt_manager/app/__init__.py">
#### `app/__init__.py`
</file>

<file path="llm_prompt_manager/app/api.py">
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Literal
from .models import Prompt, PromptCreate, PromptUpdate
from . import crud

router = APIRouter(prefix="/api/prompts", tags=["prompts"])


@router.get("/")
def list_prompts():
    return crud.get_all_prompts()


@router.get("/{prompt_id}")
def get_prompt(prompt_id: str):
    prompt = crud.get_prompt_by_id(prompt_id)
    if not prompt:
        raise HTTPException(status_code=404, detail="Prompt not found")
    return prompt


class OperationResult(BaseModel):
    status: Literal["created", "updated"]
    prompt: Prompt


@router.post("/", response_model=OperationResult)
def create_or_update_prompt(data: dict):
    """Handles both add and edit depending on if 'id' is present, with validation."""
    # Validate input using Pydantic models
    if "id" in data and data["id"]:
        valid = PromptUpdate(**data)
        updated = crud.update_prompt(valid.dict())
        if not updated:
            raise HTTPException(status_code=404, detail="Prompt not found for update")
        return {"status": "updated", "prompt": updated}
    else:
        valid = PromptCreate(**data)
        # Create a new Prompt (auto-generates UUID)
        prompt = Prompt(**valid.dict()).dict()
        created = crud.add_prompt(prompt)
        return {"status": "created", "prompt": created}


@router.delete("/{prompt_id}")
def delete_prompt(prompt_id: str):
    deleted = crud.delete_prompt(prompt_id)
    if not deleted:
        raise HTTPException(status_code=404, detail="Prompt not found for deletion")
    return {"status": "deleted"}
</file>

<file path="llm_prompt_manager/app/crud.py">
from .models import Prompt
from .utils import ensure_data_file, load_json, save_json_safe


def get_all_prompts():
    file_path = ensure_data_file()
    return load_json(file_path)


def get_prompt_by_id(prompt_id: str):
    prompts = get_all_prompts()
    for prompt in prompts:
        if prompt["id"] == prompt_id:
            return prompt
    return None


def add_prompt(prompt_data: dict):
    prompts = get_all_prompts()
    prompts.append(prompt_data)
    save_json_safe(prompts, ensure_data_file())
    return prompt_data


def update_prompt(updated_prompt: dict):
    prompts = get_all_prompts()
    for i, prompt in enumerate(prompts):
        if prompt["id"] == updated_prompt["id"]:
            prompts[i] = updated_prompt
            save_json_safe(prompts, ensure_data_file())
            return updated_prompt
    return None


def delete_prompt(prompt_id: str):
    prompts = get_all_prompts()
    updated_prompts = [p for p in prompts if p["id"] != prompt_id]
    save_json_safe(updated_prompts, ensure_data_file())
    return len(updated_prompts) < len(prompts)
</file>

<file path="llm_prompt_manager/app/main.py">
from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pathlib import Path

from .api import router as prompt_router
from .utils import ensure_data_file

app = FastAPI(title="LLM Prompt Manager")

BASE_DIR = Path(__file__).resolve().parent
templates = Jinja2Templates(directory=str(BASE_DIR / "templates"))
app.mount("/static", StaticFiles(directory=str(BASE_DIR / "static")), name="static")

# Include prompt API
app.include_router(prompt_router)

@app.on_event("startup")
def startup_event():
    ensure_data_file()

@app.get("/")
async def index(request: Request):
    """Render main UI."""
    return templates.TemplateResponse("index.html", {"request": request})
</file>

<file path="llm_prompt_manager/app/models.py">
from pydantic import BaseModel, Field
from typing import List, Optional
import uuid


class PromptBase(BaseModel):
    title: str
    description: str
    base_prompt: str
    parameters: List[str] = Field(default_factory=list)


class Prompt(PromptBase):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))


class PromptCreate(PromptBase):
    pass


class PromptUpdate(PromptBase):
    id: str
</file>

<file path="llm_prompt_manager/app/utils.py">
from pathlib import Path
import json
import os
import tempfile

DATA_FILE = Path(__file__).resolve().parent / "data" / "prompts.json"


def ensure_data_file():
    """Create prompts.json if it doesn't exist."""
    if not DATA_FILE.exists():
        DATA_FILE.parent.mkdir(parents=True, exist_ok=True)
        DATA_FILE.write_text("[]", encoding="utf-8")
    return DATA_FILE


def load_json(file_path: Path):
    """Load JSON safely."""
    if not file_path.exists():
        return []
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)


def save_json_safe(data, file_path: Path):
    """
    Write JSON atomically and corruption-proof:
    - Write to a secure temporary file in same directory
    - Flush + fsync
    - Atomically replace target file
    """
    dir_name = file_path.parent
    with tempfile.NamedTemporaryFile("w", delete=False, dir=dir_name, encoding="utf-8") as tmp:
        json.dump(data, tmp, indent=2)
        tmp.flush()
        os.fsync(tmp.fileno())
        tmp_path = tmp.name

    os.replace(tmp_path, file_path)
</file>

<file path="llm_prompt_manager/tests/test_api.py">
#### `tests/test_api.py`

from fastapi.testclient import TestClient
from llm_prompt_manager.app.main import app
import uuid


client = TestClient(app)


def test_list_prompts():
    r = client.get("/api/prompts/")
    assert r.status_code == 200
    assert isinstance(r.json(), list)


def test_create_update_delete_prompt():
    # Create
    payload = {
        "title": "Test Title",
        "description": "Test Description",
        "base_prompt": "Hello, {{name}}!",
        "parameters": ["name"]
    }
    r = client.post("/api/prompts/", json=payload)
    assert r.status_code == 200
    data = r.json()
    assert data["status"] == "created"
    created_prompt = data["prompt"]
    assert created_prompt["id"]

    # Get one
    r = client.get(f"/api/prompts/{created_prompt['id']}")
    assert r.status_code == 200
    assert r.json()["title"] == payload["title"]

    # Update
    updated = {**created_prompt, "title": "Updated Title"}
    r = client.post("/api/prompts/", json=updated)
    assert r.status_code == 200
    data = r.json()
    assert data["status"] == "updated"
    assert data["prompt"]["title"] == "Updated Title"

    # Delete
    r = client.delete(f"/api/prompts/{created_prompt['id']}")
    assert r.status_code == 200
    # Ensure it's gone
    r = client.get(f"/api/prompts/{created_prompt['id']}")
    assert r.status_code == 404
</file>

<file path="llm_prompt_manager.env/bin/activate">
# This file must be used with "source bin/activate" *from bash*
# you cannot run it directly

deactivate () {
    # reset old environment variables
    if [ -n "${_OLD_VIRTUAL_PATH:-}" ] ; then
        PATH="${_OLD_VIRTUAL_PATH:-}"
        export PATH
        unset _OLD_VIRTUAL_PATH
    fi
    if [ -n "${_OLD_VIRTUAL_PYTHONHOME:-}" ] ; then
        PYTHONHOME="${_OLD_VIRTUAL_PYTHONHOME:-}"
        export PYTHONHOME
        unset _OLD_VIRTUAL_PYTHONHOME
    fi

    # Call hash to forget past commands. Without forgetting
    # past commands the $PATH changes we made may not be respected
    hash -r 2> /dev/null

    if [ -n "${_OLD_VIRTUAL_PS1:-}" ] ; then
        PS1="${_OLD_VIRTUAL_PS1:-}"
        export PS1
        unset _OLD_VIRTUAL_PS1
    fi

    unset VIRTUAL_ENV
    unset VIRTUAL_ENV_PROMPT
    if [ ! "${1:-}" = "nondestructive" ] ; then
    # Self destruct!
        unset -f deactivate
    fi
}

# unset irrelevant variables
deactivate nondestructive

VIRTUAL_ENV="/Users/michaelbertagna/git/prompter/llm_prompt_manager.env"
export VIRTUAL_ENV

_OLD_VIRTUAL_PATH="$PATH"
PATH="$VIRTUAL_ENV/bin:$PATH"
export PATH

# unset PYTHONHOME if set
# this will fail if PYTHONHOME is set to the empty string (which is bad anyway)
# could use `if (set -u; : $PYTHONHOME) ;` in bash
if [ -n "${PYTHONHOME:-}" ] ; then
    _OLD_VIRTUAL_PYTHONHOME="${PYTHONHOME:-}"
    unset PYTHONHOME
fi

if [ -z "${VIRTUAL_ENV_DISABLE_PROMPT:-}" ] ; then
    _OLD_VIRTUAL_PS1="${PS1:-}"
    PS1="(llm_prompt_manager.env) ${PS1:-}"
    export PS1
    VIRTUAL_ENV_PROMPT="(llm_prompt_manager.env) "
    export VIRTUAL_ENV_PROMPT
fi

# Call hash to forget past commands. Without forgetting
# past commands the $PATH changes we made may not be respected
hash -r 2> /dev/null
</file>

<file path="llm_prompt_manager.env/bin/activate.csh">
# This file must be used with "source bin/activate.csh" *from csh*.
# You cannot run it directly.
# Created by Davide Di Blasi <davidedb@gmail.com>.
# Ported to Python 3.3 venv by Andrew Svetlov <andrew.svetlov@gmail.com>

alias deactivate 'test $?_OLD_VIRTUAL_PATH != 0 && setenv PATH "$_OLD_VIRTUAL_PATH" && unset _OLD_VIRTUAL_PATH; rehash; test $?_OLD_VIRTUAL_PROMPT != 0 && set prompt="$_OLD_VIRTUAL_PROMPT" && unset _OLD_VIRTUAL_PROMPT; unsetenv VIRTUAL_ENV; unsetenv VIRTUAL_ENV_PROMPT; test "\!:*" != "nondestructive" && unalias deactivate'

# Unset irrelevant variables.
deactivate nondestructive

setenv VIRTUAL_ENV "/Users/michaelbertagna/git/prompter/llm_prompt_manager.env"

set _OLD_VIRTUAL_PATH="$PATH"
setenv PATH "$VIRTUAL_ENV/bin:$PATH"


set _OLD_VIRTUAL_PROMPT="$prompt"

if (! "$?VIRTUAL_ENV_DISABLE_PROMPT") then
    set prompt = "(llm_prompt_manager.env) $prompt"
    setenv VIRTUAL_ENV_PROMPT "(llm_prompt_manager.env) "
endif

alias pydoc python -m pydoc

rehash
</file>

<file path="llm_prompt_manager.env/bin/activate.fish">
# This file must be used with "source <venv>/bin/activate.fish" *from fish*
# (https://fishshell.com/); you cannot run it directly.

function deactivate  -d "Exit virtual environment and return to normal shell environment"
    # reset old environment variables
    if test -n "$_OLD_VIRTUAL_PATH"
        set -gx PATH $_OLD_VIRTUAL_PATH
        set -e _OLD_VIRTUAL_PATH
    end
    if test -n "$_OLD_VIRTUAL_PYTHONHOME"
        set -gx PYTHONHOME $_OLD_VIRTUAL_PYTHONHOME
        set -e _OLD_VIRTUAL_PYTHONHOME
    end

    if test -n "$_OLD_FISH_PROMPT_OVERRIDE"
        set -e _OLD_FISH_PROMPT_OVERRIDE
        # prevents error when using nested fish instances (Issue #93858)
        if functions -q _old_fish_prompt
            functions -e fish_prompt
            functions -c _old_fish_prompt fish_prompt
            functions -e _old_fish_prompt
        end
    end

    set -e VIRTUAL_ENV
    set -e VIRTUAL_ENV_PROMPT
    if test "$argv[1]" != "nondestructive"
        # Self-destruct!
        functions -e deactivate
    end
end

# Unset irrelevant variables.
deactivate nondestructive

set -gx VIRTUAL_ENV "/Users/michaelbertagna/git/prompter/llm_prompt_manager.env"

set -gx _OLD_VIRTUAL_PATH $PATH
set -gx PATH "$VIRTUAL_ENV/bin" $PATH

# Unset PYTHONHOME if set.
if set -q PYTHONHOME
    set -gx _OLD_VIRTUAL_PYTHONHOME $PYTHONHOME
    set -e PYTHONHOME
end

if test -z "$VIRTUAL_ENV_DISABLE_PROMPT"
    # fish uses a function instead of an env var to generate the prompt.

    # Save the current fish_prompt function as the function _old_fish_prompt.
    functions -c fish_prompt _old_fish_prompt

    # With the original prompt function renamed, we can override with our own.
    function fish_prompt
        # Save the return status of the last command.
        set -l old_status $status

        # Output the venv prompt; color taken from the blue of the Python logo.
        printf "%s%s%s" (set_color 4B8BBE) "(llm_prompt_manager.env) " (set_color normal)

        # Restore the return status of the previous command.
        echo "exit $old_status" | .
        # Output the original/"old" prompt.
        _old_fish_prompt
    end

    set -gx _OLD_FISH_PROMPT_OVERRIDE "$VIRTUAL_ENV"
    set -gx VIRTUAL_ENV_PROMPT "(llm_prompt_manager.env) "
end
</file>

<file path="llm_prompt_manager.env/bin/Activate.ps1">
<#
.Synopsis
Activate a Python virtual environment for the current PowerShell session.

.Description
Pushes the python executable for a virtual environment to the front of the
$Env:PATH environment variable and sets the prompt to signify that you are
in a Python virtual environment. Makes use of the command line switches as
well as the `pyvenv.cfg` file values present in the virtual environment.

.Parameter VenvDir
Path to the directory that contains the virtual environment to activate. The
default value for this is the parent of the directory that the Activate.ps1
script is located within.

.Parameter Prompt
The prompt prefix to display when this virtual environment is activated. By
default, this prompt is the name of the virtual environment folder (VenvDir)
surrounded by parentheses and followed by a single space (ie. '(.venv) ').

.Example
Activate.ps1
Activates the Python virtual environment that contains the Activate.ps1 script.

.Example
Activate.ps1 -Verbose
Activates the Python virtual environment that contains the Activate.ps1 script,
and shows extra information about the activation as it executes.

.Example
Activate.ps1 -VenvDir C:\Users\MyUser\Common\.venv
Activates the Python virtual environment located in the specified location.

.Example
Activate.ps1 -Prompt "MyPython"
Activates the Python virtual environment that contains the Activate.ps1 script,
and prefixes the current prompt with the specified string (surrounded in
parentheses) while the virtual environment is active.

.Notes
On Windows, it may be required to enable this Activate.ps1 script by setting the
execution policy for the user. You can do this by issuing the following PowerShell
command:

PS C:\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

For more information on Execution Policies: 
https://go.microsoft.com/fwlink/?LinkID=135170

#>
Param(
    [Parameter(Mandatory = $false)]
    [String]
    $VenvDir,
    [Parameter(Mandatory = $false)]
    [String]
    $Prompt
)

<# Function declarations --------------------------------------------------- #>

<#
.Synopsis
Remove all shell session elements added by the Activate script, including the
addition of the virtual environment's Python executable from the beginning of
the PATH variable.

.Parameter NonDestructive
If present, do not remove this function from the global namespace for the
session.

#>
function global:deactivate ([switch]$NonDestructive) {
    # Revert to original values

    # The prior prompt:
    if (Test-Path -Path Function:_OLD_VIRTUAL_PROMPT) {
        Copy-Item -Path Function:_OLD_VIRTUAL_PROMPT -Destination Function:prompt
        Remove-Item -Path Function:_OLD_VIRTUAL_PROMPT
    }

    # The prior PYTHONHOME:
    if (Test-Path -Path Env:_OLD_VIRTUAL_PYTHONHOME) {
        Copy-Item -Path Env:_OLD_VIRTUAL_PYTHONHOME -Destination Env:PYTHONHOME
        Remove-Item -Path Env:_OLD_VIRTUAL_PYTHONHOME
    }

    # The prior PATH:
    if (Test-Path -Path Env:_OLD_VIRTUAL_PATH) {
        Copy-Item -Path Env:_OLD_VIRTUAL_PATH -Destination Env:PATH
        Remove-Item -Path Env:_OLD_VIRTUAL_PATH
    }

    # Just remove the VIRTUAL_ENV altogether:
    if (Test-Path -Path Env:VIRTUAL_ENV) {
        Remove-Item -Path env:VIRTUAL_ENV
    }

    # Just remove VIRTUAL_ENV_PROMPT altogether.
    if (Test-Path -Path Env:VIRTUAL_ENV_PROMPT) {
        Remove-Item -Path env:VIRTUAL_ENV_PROMPT
    }

    # Just remove the _PYTHON_VENV_PROMPT_PREFIX altogether:
    if (Get-Variable -Name "_PYTHON_VENV_PROMPT_PREFIX" -ErrorAction SilentlyContinue) {
        Remove-Variable -Name _PYTHON_VENV_PROMPT_PREFIX -Scope Global -Force
    }

    # Leave deactivate function in the global namespace if requested:
    if (-not $NonDestructive) {
        Remove-Item -Path function:deactivate
    }
}

<#
.Description
Get-PyVenvConfig parses the values from the pyvenv.cfg file located in the
given folder, and returns them in a map.

For each line in the pyvenv.cfg file, if that line can be parsed into exactly
two strings separated by `=` (with any amount of whitespace surrounding the =)
then it is considered a `key = value` line. The left hand string is the key,
the right hand is the value.

If the value starts with a `'` or a `"` then the first and last character is
stripped from the value before being captured.

.Parameter ConfigDir
Path to the directory that contains the `pyvenv.cfg` file.
#>
function Get-PyVenvConfig(
    [String]
    $ConfigDir
) {
    Write-Verbose "Given ConfigDir=$ConfigDir, obtain values in pyvenv.cfg"

    # Ensure the file exists, and issue a warning if it doesn't (but still allow the function to continue).
    $pyvenvConfigPath = Join-Path -Resolve -Path $ConfigDir -ChildPath 'pyvenv.cfg' -ErrorAction Continue

    # An empty map will be returned if no config file is found.
    $pyvenvConfig = @{ }

    if ($pyvenvConfigPath) {

        Write-Verbose "File exists, parse `key = value` lines"
        $pyvenvConfigContent = Get-Content -Path $pyvenvConfigPath

        $pyvenvConfigContent | ForEach-Object {
            $keyval = $PSItem -split "\s*=\s*", 2
            if ($keyval[0] -and $keyval[1]) {
                $val = $keyval[1]

                # Remove extraneous quotations around a string value.
                if ("'""".Contains($val.Substring(0, 1))) {
                    $val = $val.Substring(1, $val.Length - 2)
                }

                $pyvenvConfig[$keyval[0]] = $val
                Write-Verbose "Adding Key: '$($keyval[0])'='$val'"
            }
        }
    }
    return $pyvenvConfig
}


<# Begin Activate script --------------------------------------------------- #>

# Determine the containing directory of this script
$VenvExecPath = Split-Path -Parent $MyInvocation.MyCommand.Definition
$VenvExecDir = Get-Item -Path $VenvExecPath

Write-Verbose "Activation script is located in path: '$VenvExecPath'"
Write-Verbose "VenvExecDir Fullname: '$($VenvExecDir.FullName)"
Write-Verbose "VenvExecDir Name: '$($VenvExecDir.Name)"

# Set values required in priority: CmdLine, ConfigFile, Default
# First, get the location of the virtual environment, it might not be
# VenvExecDir if specified on the command line.
if ($VenvDir) {
    Write-Verbose "VenvDir given as parameter, using '$VenvDir' to determine values"
}
else {
    Write-Verbose "VenvDir not given as a parameter, using parent directory name as VenvDir."
    $VenvDir = $VenvExecDir.Parent.FullName.TrimEnd("\\/")
    Write-Verbose "VenvDir=$VenvDir"
}

# Next, read the `pyvenv.cfg` file to determine any required value such
# as `prompt`.
$pyvenvCfg = Get-PyVenvConfig -ConfigDir $VenvDir

# Next, set the prompt from the command line, or the config file, or
# just use the name of the virtual environment folder.
if ($Prompt) {
    Write-Verbose "Prompt specified as argument, using '$Prompt'"
}
else {
    Write-Verbose "Prompt not specified as argument to script, checking pyvenv.cfg value"
    if ($pyvenvCfg -and $pyvenvCfg['prompt']) {
        Write-Verbose "  Setting based on value in pyvenv.cfg='$($pyvenvCfg['prompt'])'"
        $Prompt = $pyvenvCfg['prompt'];
    }
    else {
        Write-Verbose "  Setting prompt based on parent's directory's name. (Is the directory name passed to venv module when creating the virtual environment)"
        Write-Verbose "  Got leaf-name of $VenvDir='$(Split-Path -Path $venvDir -Leaf)'"
        $Prompt = Split-Path -Path $venvDir -Leaf
    }
}

Write-Verbose "Prompt = '$Prompt'"
Write-Verbose "VenvDir='$VenvDir'"

# Deactivate any currently active virtual environment, but leave the
# deactivate function in place.
deactivate -nondestructive

# Now set the environment variable VIRTUAL_ENV, used by many tools to determine
# that there is an activated venv.
$env:VIRTUAL_ENV = $VenvDir

if (-not $Env:VIRTUAL_ENV_DISABLE_PROMPT) {

    Write-Verbose "Setting prompt to '$Prompt'"

    # Set the prompt to include the env name
    # Make sure _OLD_VIRTUAL_PROMPT is global
    function global:_OLD_VIRTUAL_PROMPT { "" }
    Copy-Item -Path function:prompt -Destination function:_OLD_VIRTUAL_PROMPT
    New-Variable -Name _PYTHON_VENV_PROMPT_PREFIX -Description "Python virtual environment prompt prefix" -Scope Global -Option ReadOnly -Visibility Public -Value $Prompt

    function global:prompt {
        Write-Host -NoNewline -ForegroundColor Green "($_PYTHON_VENV_PROMPT_PREFIX) "
        _OLD_VIRTUAL_PROMPT
    }
    $env:VIRTUAL_ENV_PROMPT = $Prompt
}

# Clear PYTHONHOME
if (Test-Path -Path Env:PYTHONHOME) {
    Copy-Item -Path Env:PYTHONHOME -Destination Env:_OLD_VIRTUAL_PYTHONHOME
    Remove-Item -Path Env:PYTHONHOME
}

# Add the venv to the PATH
Copy-Item -Path Env:PATH -Destination Env:_OLD_VIRTUAL_PATH
$Env:PATH = "$VenvExecDir$([System.IO.Path]::PathSeparator)$Env:PATH"
</file>

<file path="llm_prompt_manager.env/bin/fastapi">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from fastapi.cli import main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
</file>

<file path="llm_prompt_manager.env/bin/httpx">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from httpx import main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
</file>

<file path="llm_prompt_manager.env/bin/pip">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from pip._internal.cli.main import main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
</file>

<file path="llm_prompt_manager.env/bin/pip3">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from pip._internal.cli.main import main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
</file>

<file path="llm_prompt_manager.env/bin/pip3.11">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from pip._internal.cli.main import main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
</file>

<file path="llm_prompt_manager.env/bin/py.test">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from pytest import console_main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(console_main())
</file>

<file path="llm_prompt_manager.env/bin/pygmentize">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from pygments.cmdline import main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
</file>

<file path="llm_prompt_manager.env/bin/pytest">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from pytest import console_main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(console_main())
</file>

<file path="llm_prompt_manager.env/bin/uvicorn">
#!/Users/michaelbertagna/git/prompter/llm_prompt_manager.env/bin/python3.11
# -*- coding: utf-8 -*-
import re
import sys
from uvicorn.main import main
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
</file>

<file path="llm_prompt_manager.env/pyvenv.cfg">
home = /opt/anaconda3/bin
include-system-site-packages = false
version = 3.11.8
executable = /opt/anaconda3/bin/python3.11
command = /opt/anaconda3/bin/python3.11 -m venv /Users/michaelbertagna/git/prompter/llm_prompt_manager.env
</file>

<file path=".gitattributes">
# Auto detect text files and perform LF normalization
* text=auto
</file>

<file path="Dockerfile">
# Use an official Python runtime as a parent image
FROM python:3.11-slim

# Set the working directory in the container
WORKDIR /code

# Copy the requirements file into the container at /code
COPY ./requirements.txt /code/requirements.txt

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# Copy the application folder into the container at /code
COPY ./llm_prompt_manager/app /code/app

# Make port 8070 available to the world outside this container
EXPOSE 8070

# Run uvicorn when the container launches
# --host 0.0.0.0 is required to make the app accessible from outside the container
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8070"]
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 mbertagna

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="PLAN.md">
🔧 Implementation Plan for LLM Prompt Manager

1. Project Structure

Organize the app for maintainability, modularity, and clarity.

llm_prompt_manager/
│
├── app/
│   ├── main.py                # FastAPI entry point (routes, startup/shutdown)
│   ├── models.py              # Data models (Prompt schema, Pydantic models)
│   ├── crud.py                # File I/O operations for prompts.json
│   ├── api.py                 # API endpoints (CRUD operations)
│   ├── utils.py               # Helper functions (UUID, file safety, etc.)
│   ├── templates/
│   │   └── index.html         # Main Jinja2 HTML template
│   ├── static/
│   │   ├── style.css          # Optional: extra styles beyond Bootstrap
│   │   └── script.js          # Vanilla JS logic (search, substitution, copy, modals)
│   └── data/
│       └── prompts.json       # Persistent prompt data (created on first run)
│
├── tests/
│   └── test_api.py            # Unit tests for API and CRUD
│
├── requirements.txt
└── README.md


⸻

2. Backend Implementation

2.1 main.py
	•	Initialize FastAPI app.
	•	Mount static and template directories.
	•	Include router from api.py.
	•	On startup:
	•	Check if prompts.json exists; if not, create an empty array [].
	•	On shutdown:
	•	Optionally flush in-memory cache (if caching is used).

2.2 models.py
	•	Define a Prompt Pydantic model:

class Prompt(BaseModel):
    id: str
    title: str
    description: str
    base_prompt: str
    parameters: List[str]


	•	Define optional PromptCreate and PromptUpdate schemas for clean CRUD operations.

2.3 crud.py

Handles file-safe CRUD operations:
	•	Load prompts (load_prompts())
	•	Save prompts (save_prompts_safe())
	•	Write to a temporary file (e.g., prompts.tmp.json), then rename to prompts.json.
	•	Add, edit, delete functions that manipulate the list and call save.

Example:

def save_prompts_safe(prompts, file_path):
    tmp = file_path + ".tmp"
    with open(tmp, 'w') as f:
        json.dump(prompts, f, indent=2)
    os.replace(tmp, file_path)


⸻

3. API Implementation (api.py)

Operation	Method	Endpoint	Behavior
List all prompts	GET	/api/prompts	Return all prompts
Get one prompt	GET	/api/prompts/{id}	Return prompt by ID
Add prompt	POST	/api/prompts	Create a new prompt, generate UUID
Update prompt	POST	/api/prompts	Overwrite existing prompt matching ID
Delete prompt	DELETE	/api/prompts/{id}	Remove from file and memory

Use FastAPI’s built-in response models for automatic validation and OpenAPI documentation.

⸻

4. Frontend Implementation

4.1 index.html (Jinja2)
	•	Simple two-panel layout:
	•	Left panel: list of prompt titles with a search box.
	•	Right panel: detail view (title, description, editable parameters, live assembled output).
	•	Use Bootstrap layout grid (col-md-4 / col-md-8) and modals for “Add/Edit Prompt.”

4.2 script.js

Implements:
	•	Fetch all prompts from /api/prompts and populate sidebar.
	•	Filter list client-side using a search input (text matching title/description).
	•	Load selected prompt into detail view.
	•	Dynamically create parameter input boxes (textarea per parameter).
	•	Real-time substitution using:

const assembled = basePrompt.replace(/{{(.*?)}}/g, (_, key) => formValues[key] || '');


	•	Copy-to-clipboard functionality with navigator.clipboard.writeText().

4.3 Modal forms
	•	Triggered by “Add” or “Edit” buttons.
	•	Support dynamic parameter addition/removal.
	•	On submit, POST to /api/prompts.

⸻

5. Data Flow Overview
	1.	User opens app → Frontend fetches all prompts via /api/prompts.
	2.	User selects a prompt → JS loads prompt details and parameters.
	3.	User types into parameter boxes → JS substitutes values live in assembled preview.
	4.	User clicks “Copy” → Prompt text copied to clipboard.
	5.	User adds/edits/deletes a prompt → Backend updates prompts.json safely.

⸻

6. Testing Plan

6.1 Unit Tests
	•	CRUD operations on test JSON files (ensure safe overwrite).
	•	API endpoint tests with FastAPI TestClient.

6.2 Frontend Tests (optional)
	•	Basic JS integration test using Playwright or Cypress (optional for local utility).

⸻

7. Enhancement Hooks (Future)
	•	Add categories/tags for better organization.
	•	Export/import functionality (JSON).
	•	Version history (simple diff system in file).
	•	Parameter templates or autocomplete.

⸻

8. Implementation Order
	1.	Initialize project structure.
	2.	Implement models.py, crud.py, api.py.
	3.	Build FastAPI app (main.py).
	4.	Create index.html with static JS logic.
	5.	Connect frontend to API.
	6.	Add modal forms and live substitution logic.
	7.	Implement file safety and basic tests.
	8.	Polish UI (Bootstrap, responsiveness).
</file>

<file path="README.md">
# LLM Prompt Manager

A lightweight local web app for managing and assembling reusable LLM prompts.

## Quick Start
```bash
python3.11 -m venv llm_prompt_manager.env
source llm_prompt_manager.env/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

Open the app at `http://127.0.0.1:8000/`.

## Features
- Manage prompts with title, description, base prompt, and parameters.
- Search prompts client-side.
- Dynamic parameter inputs with live substitution into the base prompt using `{{parameter_name}}` syntax.
- Copy the final assembled prompt to clipboard.
- File-backed storage (`app/data/prompts.json`) with safe atomic writes.

## API
- GET `/api/prompts/`: List all prompts
- GET `/api/prompts/{id}`: Get a prompt by ID
- POST `/api/prompts/`: Create or update (include `id` for update)
- DELETE `/api/prompts/{id}`: Delete a prompt

## Run tests
```bash
python -m pytest -q llm_prompt_manager/tests
```
</file>

<file path="requirements.txt">
fastapi
uvicorn
jinja2
python-multipart
pytest
httpx
</file>

<file path="SPEC.md">
Concise Application Specification
1. Core Architecture & Technology
| Component | Detail | Rationale |
|---|---|---|
| Application Type | Local Web Application (FastAPI) | Provides a searchable interface with dynamic forms. |
| Language | Python | Portable and simple for utility development. |
| Frontend | Jinja2 Templates, HTML, Bootstrap CSS, Vanilla JavaScript | Simple and dependency-free for client-side interactivity. |
| Persistence | File I/O only (No external database) | Ensures maximum portability via Git; data is stored next to the code. |
| File Safety | Temporary file write mechanism (FastAPI backend) | Prevents data corruption of prompts.json during save operations. |
2. Data Structure & Storage
| Element | Detail | Rationale |
|---|---|---|
| Data File | prompts.json | Human-readable, easy to version control and parse. |
| Prompt Structure | JSON array of objects | Stores all required metadata for each prompt. |
| Placeholders | Jinja-style: {{parameter_name}} | Clear, standard syntax for substitution within the base_prompt. |
| Prompt ID | UUID (FastAPI generated) | Ensures a unique key for CRUD operations. |
3. User Interface (UI) Features
| Feature | Detail | Implementation |
|---|---|---|
| Prompt Listing | Left-hand panel displays all prompts. | Uses a simple HTML list and client-side JavaScript to load details. |
| Search/Filter | Real-time text input filter. | Client-side JavaScript (in index.html) filters the visible list items based on title/description. |
| Parameter Inputs | All parameters use a multi-line, scrollable textarea element. | Simple design choice that accommodates both short and long inputs. |
| Prompt Assembly | Real-time substitution. | Client-side JavaScript updates the output box immediately on every keystroke. |
| Final Output | Copy Button (sole function). | Copies the final assembled prompt text to the user's clipboard via navigator.clipboard.writeText(). |
4. Data Management (CRUD)
| Operation | Method / Endpoint | Detail |
|---|---|---|
| Add New Prompt | POST /api/prompts | Opens a modal form, generates a new uuid, and saves the entry. |
| Edit Existing | POST /api/prompts | Opens the modal, loads existing data via GET /api/prompts/{id}, and updates the entry by matching the existing ID. |
| Delete Prompt | DELETE /api/prompts/{id} | Removes the entry from the in-memory list and persists the change to prompts.json. |
| Parameter Editing | Integrated into the Edit modal | Dynamic UI allows users to add, edit, and remove parameter fields on the fly using vanilla JavaScript. |
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor  
#  Cursor is an AI-powered code editor.`.cursorignore` specifies files/directories to 
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

repomix-output.xml
</file>

<file path="pull_and_restart.sh">
#!/bin/bash

# This script stops and removes the Docker container, pulls the latest from main, and restarts.

echo "🚀 Starting deployment script..."

# 1. Stop and remove the existing container if it exists
echo "--- Stopping and removing existing 'my-prompt-manager' container... ---"
docker rm -f my-prompt-manager || echo "Container not found, continuing."

# 2. Pull the latest changes from the main branch
echo "--- Pulling latest changes from git repository (main branch)... ---"
git pull origin main

# 3. Rebuild the Docker image
echo "--- Rebuilding the 'prompt-manager' Docker image... ---"
docker build -t prompt-manager .

# 4. Start the new container
echo "--- Starting new container... ---"
docker run -d -p 8070:8070 --name my-prompt-manager -v "$(pwd)/llm_prompt_manager/app/data:/code/app/data" prompt-manager

echo "✅ Deployment complete! Container is running with the latest code at http://127.0.0.1:8070/."
</file>

<file path="push_and_restart.sh">
#!/bin/bash

# This script pushes local changes to git, and then stops, removes, and restarts the Docker container.
# It uses a provided commit message or a default one if none is given.

echo "🚀 Starting deployment script..."

# 1. Define the commit message
# Use the first argument ($1) if it's provided, otherwise use the default message.
COMMIT_MSG="${1:-prompts edited}"

# 2. Stop and remove the existing container if it exists
echo "--- Stopping and removing existing 'my-prompt-manager' container... ---"
docker rm -f my-prompt-manager || echo "Container not found, continuing."

# 3. Add, commit, and push changes to git
echo "--- Pushing changes to git with message: '$COMMIT_MSG' ---"
git add .
git commit -m "$COMMIT_MSG"
git push origin main

# 4. Rebuild the Docker image
echo "--- Rebuilding the 'prompt-manager' Docker image... ---"
docker build -t prompt-manager .

# 5. Start the new container
echo "--- Starting new container... ---"
docker run -d -p 8070:8070 --name my-prompt-manager -v "$(pwd)/llm_prompt_manager/app/data:/code/app/data" prompt-manager

echo "✅ Deployment complete! Changes are pushed and the container is running at http://127.0.0.1:8070/."

# To solve permission issues:
# sudo chmod 644 llm_prompt_manager/app/data/prompts.json
# sudo chown $(whoami):$(whoami) llm_prompt_manager/app/data/prompts.json
</file>

<file path="llm_prompt_manager/app/data/prompts.json">
[
  {
    "title": "Coding Agent Prompt Creation",
    "description": "A prompt which can be provided to a LLM-based chatbot which has context about a feature to implement. The result of providing this prompt to the chatbot can be passed to a coding agent (e.g., Cursor, Gemini CLI, Claude Code, etc.).",
    "base_prompt": "Create a **prompt** that will be given to a coding agent whose job is to **implement/integrate this specific feature/change** into the codebase.\nYour prompt must clearly instruct the coding agent on how to reason about, plan, and conceptually integrate the feature while avoiding unnecessary low-level details.\n\nWhen generating this prompt, keep the original intent and structure below exactly as described.\n\n---\n\n### 1. Feature Implementation Focus\n\nInstruct the coding agent to implement the specified feature into the codebase. Emphasize **conceptual clarity and overall architectural integration**, while allowing flexibility for low-level implementation choices (e.g., helper functions, naming, and internal logic).\nThe prompt must clearly tell the coding agent to **avoid providing overly specific implementation details** unless absolutely required for correct integration.\n\n---\n\n### 2. Required Structure of the Coding Agent\u2019s Response\n\nThe coding agent\u2019s response should strictly follow this structure:\n\n#### **1. Feature Overview**\n\nDirect the agent to provide a **clear and concise conceptual overview** describing the feature\u2019s purpose, scope, and user value.\n\n#### **2. Conceptual Breakdown of Codebase Changes (Without Code)**\n\nInstruct the agent to give a **comprehensive, high-level conceptual breakdown** of all necessary changes required to integrate the feature into the codebase.\nThis must include the **conceptual roles** of any new classes, methods, or functions, and identify which existing components they interact with or modify.\nMake clear that **no code or low-level details** should be included\u2014focus only on what needs to be done and where it fits conceptually.\n\n#### **3. Architectural Alignment and Guidance**\n\nTell the agent to provide **high-level architectural guidance** on how the proposed changes align with and respect the current system\u2019s design (e.g., patterns, modularity, and data flow).\nThe response must emphasize **modularity**\u2014each conceptual unit should serve a single, specific purpose.\n\n---\n\n### 3. General Coding Style and Deliverables\n\nIn the generated prompt, include the following explicit coding style and deliverable instructions for the coding agent:\n\n* **Docstrings:** Use **NumPy-style docstrings** for all classes, methods, and functions. Keep them **clear and concise**.\n* **Comments:** Remove unnecessary comments; only include those required to explain complex or non-obvious logic.\n* **Modularity:** Each function or method must perform a **single, specific task**.\n* **Emojis:** Avoid the use of emojis.\n\n---\n\n### 4. Context Files\n\nThe prompt should also include a section listing the files that will be provided to the coding agent for context. Use a placeholder such as:\n\n* [List of all necessary files (e.g., `src/module_a/file.py`, `tests/test_file.py`, etc.)]",
    "parameters": [],
    "id": "a9410a06-1b44-4fbc-9e26-9e8426faaa4b"
  },
  {
    "title": "Project Spec Builder",
    "description": "A chatbot prompt which can be used to help create a spec for any software project",
    "base_prompt": "**Idea Overview:**\nI want to build a software project that { {{PROJECT_IDEA}} }.\n\n---\n\n### **Areas to Explore**\n\nBefore creating a detailed specification, I need to understand the following:\n\n* **Purpose and scope** \u2014 what the project should accomplish and who it\u2019s for\n* **Core functionality** \u2014 the main features and capabilities\n* **Technology preferences** \u2014 programming languages, frameworks, tools, or platforms to use\n* **Architecture and infrastructure** \u2014 how components interact, data flow, hosting, and deployment\n* **Integration needs** \u2014 any external systems, APIs, or data sources to connect with\n* **User interaction and interface** \u2014 how users will interact with the system (CLI, GUI, web app, API, etc.)\n* **Performance and scalability** \u2014 expected load, performance goals, and scaling considerations\n* **Security and privacy requirements** \u2014 any specific standards, data protection, or authentication needs\n* **Testing and maintenance** \u2014 expectations for testing, monitoring, or long-term upkeep\n\n---\n\n### **Your Task**\n\n#### **Phase 1: Discovery (Before Building the Specification)**\n\n* Ask **yes/no questions one at a time** to gather information about each of the areas above.\n* **Wait for the user\u2019s response** before asking the next question.\n* Do **not** create or outline the specification yet.\n* When you believe you\u2019ve gathered sufficient details, **propose that you have enough information** and ask the user to confirm before proceeding.\n* Only move to Phase 2 if the user **explicitly agrees** that you have enough information.\n\n#### **Phase 2: Specification (After User Agreement)**\n\n* Create the specification **only after** receiving explicit user confirmation.\n* Do **not** mix questioning with specification writing.\n* Write a **concise, detailed, and structured specification** that accurately reflects all information gathered during Phase 1.\n",
    "parameters": [
      "PROJECT_IDEA"
    ],
    "id": "f3974a6c-3524-4afb-9738-4c1ff01c7f34"
  },
  {
    "title": "Coding Agent Prompt Creation for New Codebase Architecture",
    "description": "",
    "base_prompt": "**Codebase:** { {{CODEBASE}} }\n\n# **Your Goal:** Design a modular, DRY, and scalable organization structure for upcoming feature integrations.\n\n---\n\n### Primary Objective\n\nYou are tasked with proposing **codebase organization options** for [CODEBASE_NAME_PLACEHOLDER] one at a time.\nEach proposal should aim for **maximal modularity, clarity, and architectural consistency** with the presumed or provided structure of the codebase.\n\nAt each iteration:\n\n1. Provide **one** option for organization (not multiple at once).\n2. Wait for my feedback.\n3. If I request changes or refinements, incorporate them into the next iteration.\n4. When I explicitly approve an option, you will then generate a **final implementation prompt** for a coding agent as described below.\n\n---\n\n### Step 1: Iterative Codebase Organization Proposal\n\nEach proposal should include:\n\n#### 1. Conceptual Structure Overview\n\nProvide a **concise conceptual map** of how the system\u2019s architecture and components will be restructured or reorganized.\nExplain the purpose of each new or refactored module, class, or directory and how they fit into the broader design.\n\n#### 2. Key Modules and Responsibilities\n\nList the **key components** (modules, classes, or functions) and describe their **high-level conceptual roles** \u2014 what each does and how they interact \u2014 **without suggesting any specific implementation or code**.\n\n#### 3. Design Rationale\n\nJustify **why** this architectural approach improves modularity, reusability, maintainability, and scalability.\nReference design principles (e.g., SOLID, separation of concerns, dependency inversion) where appropriate.\n\n#### 4. DRYness and Extensibility Check\n\nExplicitly explain how the proposed structure:\n\n* Eliminates redundancy and tight coupling\n* Supports extensibility and maintainability\n* Aligns with or improves upon the codebase\u2019s existing patterns and conventions\n\nAfter presenting this, stop and ask:\n\n> \u201cWould you like to approve this organization or request revisions before proceeding?\u201d\n\n---\n\n### Step 2: Once Approved \u2014 Generate the Implementation Prompt\n\nWhen I approve a structure, you will output the following **final implementation prompt** (filled in appropriately):\n\n---\n\n#### **Implementation Prompt for Coding Agent**\n\n**Prompt:**\n\n> Implement the approved architectural restructuring in the codebase.\n> **Focus on conceptual clarity, structural integrity, and modular organization**, leaving detailed implementation choices and low-level logic (e.g., helper utilities, variable names, or internal optimizations) to your discretion.\n> **Avoid overly specific implementation details** unless they are essential to preserve architectural correctness.\n\nYour response must strictly adhere to the following structure and content requirements:\n\n---\n\n### 1. Architectural Restructure Overview\n\nProvide a **clear and concise conceptual overview** of the architectural restructuring \u2014 its purpose, motivation, and expected impact on the codebase (e.g., improved modularity, maintainability, or scalability).\n\n### 2. Conceptual Breakdown of Changes (Without Code)\n\nProvide a **comprehensive, high-level conceptual breakdown** of the restructuring steps.\nDescribe which components, modules, or directories are being added, removed, or reorganized, and how they interact in the new structure.\n**Avoid suggesting specific code.** Focus on *what* needs to change and *where* it fits conceptually.\n\n### 3. Architectural Alignment and Guidance\n\nOffer **specific, high-level guidance** on how the restructuring aligns with and strengthens the existing architecture (e.g., enforcing separation of concerns, design patterns, or layering principles).\n**Emphasize modularity** \u2014 each module or class should have a single, well-defined purpose.\n\n---\n\n### General Coding Style and Deliverables\n\nAdhere to the following style guidelines in the restructured code:\n\n* **Docstrings:** Use **NumPy docstring format** for all classes, methods, and functions where applicable. Ensure the verbiage is **concise**.\n* **Comments:** **Remove all unnecessary comments.** Only include comments for complex, non-obvious logic if absolutely required for clarity.\n* **Modularity:** Ensure the architecture enforces strong modular boundaries \u2014 each component should perform a **specific, single role**.\n* **Emojis:** Avoid the use of emojis.\n\n---\n\n### Context Files\n\nThe following files will be provided as context for accurate and efficient restructuring:\n\n* [List of all necessary files (e.g., `src/module_a/file.py`, `core/architecture.py`, `tests/test_integration.py`, etc.)]\n\n---\n\n### Step 3: Iterative Refinement (Optional)\n\nIf requested, you may help refine or adapt the generated implementation prompt (e.g., adjusting restructuring scope, architecture focus, or file list) before it is finalized for the coding agent.\n",
    "parameters": [
      "CODEBASE"
    ],
    "id": "b4e84abe-0bbe-48ba-b037-10417ddab48f"
  },
  {
    "title": "Commit Prompt",
    "description": "",
    "base_prompt": "Create a commit message that follows exactly the same format and structure as the provided example.\nUse **simple, clear language** and keep all bullet points short and direct.\nAvoid changing any section headers, indentation, or layout \u2014 your goal is to match the style of the example exactly.\nAvoid using any markdown formatting such as bold text, code blocks, or lists. Use plain text only.\nReturn the final commit message **inside a text box**.\n\nExample commit message:\n{ {{example_commit_message}} }\n\nImplementation summary:\n{ {{implementation_summary}} }\n\nImplementation code:\n{ {{implementation_code}} }\n\nComplete codebase:\n{ {{complete_codebase}} }",
    "parameters": [
      "example_commit_message",
      "implementation_summary",
      "implementation_code",
      "complete_codebase"
    ],
    "id": "2f3eda1a-48f8-460a-b9e7-3b1801c1df0b"
  },
  {
    "title": "Atomic Git History Generation (Interactive)",
    "description": "A three-stage, approval-gated workflow to transform a single, large code change (before/after diff) into a clean, logical set of atomic commits organized across ordered topic branches. This strategy supports a clean, rebasable dependency tree.",
    "base_prompt": "I have made changes to the **{{TOPIC}}** project. My goal is to organize these changes into a clean, logical set of **atomic Git commits** across multiple **topic branches** for a final push.\n\nYour process will consist of three distinct tasks, each requiring my approval before proceeding to the next.\n\n### Task 1: Code Difference Analysis\n\n1.  **Analyze the changes:** Review the `CODE_BEFORE` and `CODE_AFTER` sections to understand the exact differences in the codebase.\n2.  **Report findings:** Summarize the nature and scope of the changes (e.g., \"Feature X added,\" \"Refactoring of Y module,\" \"Bug Z fixed\").\n3.  **Output:** Present a summary of the differences.\n      * **STOP:** Wait for my approval before proceeding to Task 2. I may ask for revisions or clarifications at this stage.\n\n-----\n\n### Task 2: High-Level Git Organization\n\n  * *This task proceeds only after my approval of Task 1.*\n\n1.  **Determine topics:** Group the changes identified in Task 1 into logical, high-level **topic branches** (e.g., `feature/user-auth`, `refactor/api-cleanup`).\n2.  **Establish ordering:** Decide on the most logical and narrative **ordering** for these topic branches, ensuring a clean dependency tree where each branch builds on the previous one.\n3.  **Output:** Provide a numbered list of the proposed topic branches and their intended order.\n      * **STOP:** Wait for my approval before proceeding to Task 3. I may ask for revisions to the branch structure or ordering.\n\n-----\n\n### Task 3: Atomic Commit Generation\n\n  * *This task proceeds only after my approval of Task 2.*\n\n1.  **Generate atomic commits:** For each approved topic branch, break down the changes into the smallest possible **atomic commits**. The commits must be ordered to tell a clear, logical story.\n2.  **Format the output:** For each generated atomic commit, present two items:\n      * A **one-line commit summary** (max 50 characters).\n      * A list of the specific **files or code snippets** to be included in that commit (i.e., the diff to be staged). Clearly indicate which topic branch the commit belongs to.\n3.  **Dependency Note:** I will be rebasing each successive new topic branch onto the previous one. The commit structure *must* support this clean, sequential dependency tree.\n\n-----\n\n## Code Base\n\nCODE BEFORE:\n{ {{CODE_BEFORE}} }\n\nCODE AFTER:\n{ {{CODE_AFTER}} }",
    "parameters": [
      "TOPIC",
      "CODE_BEFORE",
      "CODE_AFTER"
    ],
    "id": "f22f36c0-f0c7-4d82-ac9a-c474e6afcfec"
  },
  {
    "title": "Add NumPy-Style Docstrings Without Modifying Code",
    "description": "",
    "base_prompt": "Add complete and correct NumPy-style docstrings to the provided code.\n\nFollow these exact rules carefully:\n\n1. **File-level docstring:** At the very top of each file, include a brief description of the file\u2019s purpose, main classes/functions, and any important usage notes.\n2. **Class docstrings:** Describe what the class represents, its main attributes, and its intended use. Include an **Attributes** section listing all key attributes and their types.\n3. **Function and method docstrings:** Include the following NumPy-style sections where applicable:\n   * **Parameters:** List every parameter, its type, and a short, clear explanation.\n   * **Returns:** Describe the return value(s) and their types.\n   * **Raises:** List possible exceptions, if any.\n   * **Examples:** Add a simple example only if it helps clarify functionality.\n4. Use **simple, direct, and concise** language throughout.\n5. **Avoid emojis** and unnecessary phrasing.\n6. **Avoid changing any of the code itself** \u2014 only insert docstrings.\n7. Maintain consistent indentation and formatting so docstrings align properly within the code.\n\nCode:\n{\n{{CODE}}\n}",
    "parameters": [
      "CODE"
    ],
    "id": "039cd1de-bbc8-4529-ae09-a1ade618cee9"
  }
]
</file>

</files>
